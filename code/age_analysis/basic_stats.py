import pandas as pd
import re
from pathlib import Path
import shutil

INPUT_DIR = "filtered_ages"

FP_PATTERN = re.compile(
    rf"{INPUT_DIR}/(?P<year>\d{{4}})/age_(?P<match_type>[\w_]+).csv"
)


def combine_winners_losers(df):
    """
    This converts a dataframe with columns:
    winner_id, winner_name, winner_age, loser_id, loser_name, loser_age
    to a dataframe with columns:
    id, name, age
    By renaming the columns and pasting the loser data below the winner data
    """
    winners = df[["winner_id", "winner_name", "winner_age"]].rename(
        columns={
            "winner_id": "id",
            "winner_name": "name",
            "winner_age": "age",
        }
    )

    losers = df[["loser_id", "loser_name", "loser_age"]].rename(
        columns={
            "loser_id": "id",
            "loser_name": "name",
            "loser_age": "age",
        }
    )

    # Simply pastes the rows together. The ignore_index makes it so that the
    # index of the loser portion of data does not start at 0, it starts at
    # len(winners).
    return pd.concat([winners, losers], ignore_index=True)


def main():
    data_path = Path(INPUT_DIR)
    if not data_path.exists():
        print(
            "You need to run clean_height_data.py first, this script depends on the data generated by it."
        )
        return 1
    # Only the id is needed to identify the player, but it is database specific
    # so to search online for a player you need a name. More readable also.
    cols = [
        "winner_id",
        "winner_name",
        "winner_age",
        "loser_id",
        "loser_name",
        "loser_age",
    ]

    dataframes = []
    for fn in data_path.rglob("*.csv"):
        fn_match = re.search(FP_PATTERN, str(fn))
        if fn_match:
            print(f"Processing: {fn}â€¦")
            match_type = fn_match.group("match_type")
            year = fn_match.group("year")

            df = pd.read_csv(fn, usecols=cols)  # pyright: ignore
            combined = combine_winners_losers(df)
            dataframes.append(combined)
    df = pd.concat(dataframes, ignore_index=True)
    print(df["age"].mean())
    print(df["age"].median())

    youngest_idx = df["age"].idxmin()
    oldest_idx = df["age"].idxmax()

    print("Youngest:", df.loc[youngest_idx, "name"], df.loc[youngest_idx, "age"])
    print("Oldest:", df.loc[oldest_idx, "name"], df.loc[oldest_idx, "age"])
    sus = df[(df["age"] < 16) | (df["age"] > 50)]
    sus[["name", "age"]].sort_values("age")
    print("Outlier match rows:", len(sus))
    print("Unique outlier players:", sus["id"].nunique())
    print("Unique players total:", df["id"].nunique())
    print(
        "Share of players with any outlier:", sus["id"].nunique() / df["id"].nunique()
    )
    sus_young = df[df["age"] < 16]
    sus_old = df[df["age"] > 45]

    print("Young outlier match rows:", len(sus_young))
    print("Old outlier match rows:", len(sus_old))

    print("Young outlier players:", sus_young["id"].nunique())
    print("Old outlier players:", sus_old["id"].nunique())

    return 0


if __name__ == "__main__":
    raise SystemExit(main())
