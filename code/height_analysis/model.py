import pandas as pd
import re
import statsmodels.formula.api as smf
from sklearn.metrics import accuracy_score, roc_auc_score, log_loss, brier_score_loss
from pathlib import Path


CSV_DIR = "csv"


def init_out_dir():
    p = Path(CSV_DIR)
    p.mkdir(parents=True, exist_ok=True)


def get_formulas():
    """
    This function serves to separate the formulas from the rest of the code.
    A lot of them were generated by ChatGPT so I could see what did well and
    what did not.
    """
    formulas = []
    # C is category. I More or less just creates a new column based on the
    # formula inside ().

    # Differences.
    formulas.append(
        """
    win ~
        dh
    """
    )
    formulas.append(
        """
    win ~
        I(dh * year)
    """
    )
    formulas.append(
        """
    win ~
        dh + year
    """
    )
    # Base splines
    for i in range(4, 10):
        formulas.append(
            f"""
        win ~
            bs(p1_ht, df={i}) +
            bs(p2_ht, df={i})
        """
        )
        formulas.append(f"win ~ cr(dh, df={i})")
        formulas.append(f"win ~ bs(dh, df={i})")

    formulas.append("win ~ dh + I(dh**2)")

    return formulas


def test(train_df, test_df, formulas):
    rows = []
    for formula in formulas:
        print(f"Formula: {formula}")
        model = smf.logit(formula, data=train_df).fit()

        # How probable is our test data according to the model?
        p = model.predict(test_df)
        print(model.summary())

        y = test_df["win"].astype(int).values
        y_hat = (p >= 0.5).astype(int)

        row = {
            "formula": formula,
            "accuracy_score": accuracy_score(y, y_hat),
            "log_loss": log_loss(y, p),
            "brier_score_loss": brier_score_loss(y, p),
            "roc_auc_score": roc_auc_score(y, p),
        }
        print(f"accuracy: {round(row["accuracy_score"] * 100, 2)}")
        print(f"logloss: {row["log_loss"]}")
        print(f"brier: {row["brier_score_loss"]}")
        print(f"auc: {row["roc_auc_score"]}")

        rows.append(row)
    return rows


def main():
    path = Path(f"{CSV_DIR}/logit.csv")
    if not path.is_file():
        print(
            "logit.csv Is missing, please run logit_csv.py before running this script."
        )
        return 1
    init_out_dir()
    df = pd.read_csv(path)

    len_raw = len(df)
    print(f"Length raw input: {len_raw}")
    # Won't touch categories.
    df.dropna(inplace=True)
    len_non_na = len(df)
    # Should be none
    print(
        f"dropna dropped {len_raw - len_non_na} rows, which is "
        f"{((len_raw - len_non_na) / len_raw * 100):.1f}%."
    )

    # This can be done inside the formulas, but far more convenient to just make
    # columns derived from the data.
    df["dh"] = df["p1_ht"] - df["p2_ht"]
    df["abs_dh"] = df["dh"].abs()
    df["dh_pos"] = (df["dh"] > 0).astype(int)
    df["mean_ht"] = (df["p1_ht"] + df["p2_ht"]) / 2

    # So we can split test and train based on date.
    df["year"] = pd.to_numeric(df["year"], errors="coerce")
    df.dropna(subset=["year"], inplace=True)
    df["year"] = df["year"].astype(int)

    train_years = set(range(1991, 2022))
    test_years = {2022, 2023, 2024}

    is_test_year = df["year"].isin(test_years)
    is_train_year = df["year"].isin(train_years)

    train_df = df.loc[is_train_year].copy()
    test_df = df.loc[is_test_year].copy()
    formulas = get_formulas()

    rows = test(train_df, test_df, formulas)
    # Otherwise the formula will display like it was defined in get_formulas(),
    # i.e. multiple lines.
    for row in rows:
        row["formula"] = re.sub(r"\s+", " ", row["formula"]).strip()
    results_df = pd.DataFrame(rows)

    results_df = results_df[
        ["formula", "accuracy_score", "log_loss", "brier_score_loss", "roc_auc_score"]
    ]

    results_df.to_csv(f"{CSV_DIR}/model_results.csv", index=False)

    return 0


if __name__ == "__main__":
    raise SystemExit(main())
